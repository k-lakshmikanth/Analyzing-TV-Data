{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPNk2ndZ7d3hSErX2nElga3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0CA1LaRWxGyN"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gpt4all"
      ],
      "metadata": {
        "id": "Ca0UDCKn5xEH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, LLMChain\n",
        "# from langchain.llms import GPT4All\n",
        "from gpt4all import GPT4All\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
      ],
      "metadata": {
        "id": "i8_HcWc5xg52"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer: Let's think step by step.\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
      ],
      "metadata": {
        "id": "EqvQEGs1ziCN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"ggml-model-gpt4all-falcon-q4_0\""
      ],
      "metadata": {
        "id": "wCXndGglznXO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks support token-wise streaming\n",
        "callbacks = [StreamingStdOutCallbackHandler()]\n",
        "\n",
        "# Verbose is required to pass to the callback manager\n",
        "llm = GPT4All(model_name,\\\n",
        "              allow_download=True,\\\n",
        "            #   callbacks=callbacks,\\\n",
        "            #   verbose=True\\\n",
        "              )\n",
        "\n",
        "# If you want to use a custom model add the backend parameter\n",
        "# Check https://docs.gpt4all.io/gpt4all_python.html for supported backends\n",
        "# llm = GPT4All(model=local_path, backend=\"gptj\", callbacks=callbacks, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSCgcn5o2eBL",
        "outputId": "0fe7c098-2e45-4998-f2f8-0d43c712cbe7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found model file at  /root/.cache/gpt4all/ggml-model-gpt4all-falcon-q4_0.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "local_path = \"/root/.cache/gpt4all/ggml-model-gpt4all-falcon-q4_0.bin\"\n",
        "\n",
        "from langchain.llms import GPT4All\n",
        "\n",
        "llm = GPT4All(model=local_path, callbacks=callbacks, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NH63CmW-_dqd",
        "outputId": "2ef10465-2c80-4214-d656-73b1542ac8bc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found model file at  /root/.cache/gpt4all/ggml-model-gpt4all-falcon-q4_0.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain = LLMChain(prompt=prompt, llm=llm)"
      ],
      "metadata": {
        "id": "oGVecpH7BbdC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What NFL team won the Super Bowl in the year Justin Bieber was born?\"\n",
        "\n",
        "llm_chain.run(question)"
      ],
      "metadata": {
        "id": "21dGuj0nBcUN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "2448b22b-f411-4fd6-b2c3-2a28327eeb55"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "1. Justin Bieber was born on March 1, 1994. \n",
            "2. The first Super Bowl after his birthday was played on January 26, 2003. \n",
            "3. The Tampa Bay Buccaneers won the Super Bowl in 2003."
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' \\n1. Justin Bieber was born on March 1, 1994. \\n2. The first Super Bowl after his birthday was played on January 26, 2003. \\n3. The Tampa Bay Buccaneers won the Super Bowl in 2003.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}